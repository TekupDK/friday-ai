# OpenRouter Models Integration - Phase Plan

## ðŸ“‹ Oversigt

Integration af 6 nye free OpenRouter AI modeller med 100% accuracy ratings og evaluering af Friday AI systemet.

**Status:** ðŸŸ¢ Phase 1-2 Complete | ðŸŸ¡ Phase 3 In Progress

---

## âœ… Phase 1: Model Integration (COMPLETE)

**MÃ¥l:** Integrere nye OpenRouter modeller i systemet

### Completed Tasks:

- [x] TilfÃ¸j 6 nye modeller til `AIModel` type
  - GLM-4.5 Air (100% accuracy)
  - GPT-OSS 20B (100% accuracy)
  - DeepSeek Chat v3.1 (advanced reasoning)
  - MiniMax M2 (fast & efficient)
  - Qwen3 Coder (code specialist)
  - Kimi K2 (long context - 200K tokens)

- [x] Opdater `MODEL_ROUTING_MATRIX`
  - Chat â†’ GLM-4.5 Air
  - Email drafting â†’ GLM-4.5 Air
  - Email analysis â†’ DeepSeek v3.1
  - Code generation â†’ Qwen3 Coder
  - Complex reasoning â†’ DeepSeek v3.1
  - Long context â†’ Kimi K2

- [x] Opret model mapping fil (`model-mappings.ts`)
  - Internal names â†’ OpenRouter IDs
  - Model metadata (context, pricing, capabilities)

- [x] Opdater environment filer
  - `.env` â†’ GLM-4.5 Air som default
  - `.env.dev` â†’ GLM-4.5 Air som default
  - `.env.prod.template` â†’ Production config
  - Bevaret eksisterende API keys

- [x] Opdater client-side config
  - `ai-config.ts` â†’ GLM-4.5 Air reference
  - `ai.ts` â†’ Active model constant

**Deliverables:** âœ…

- 6 nye modeller tilgÃ¦ngelige
- Task-based routing konfigureret
- Environment filer opdateret med nye defaults

---

## âœ… Phase 2: Evaluation Setup (COMPLETE)

**MÃ¥l:** OpsÃ¦tte evaluation frameworks til testing

### Completed Tasks:

- [x] Promptfoo configuration (`ai-eval-config.yaml`)
  - 5 test providers konfigureret
  - 12 test prompts (dansk business context)
  - Automatisk sammenligning af modeller
  - Output til HTML rapport

- [x] DeepEval test suite (`tests/ai/deepeval-test.py`)
  - Answer Relevancy metric
  - Faithfulness metric
  - Hallucination detection
  - 4 test cases (email, chat, invoice, calendar)

- [x] Dokumentation
  - `AI_MODEL_SELECTION_GUIDE.md` (466 linjer)
  - `AI_MODELS_UPGRADE_SUMMARY.md` (200 linjer)
  - Omfattende migration guide
  - Best practices for model selection

**Deliverables:** âœ…

- Promptfoo eval config klar
- DeepEval Python tests klar
- Komplet dokumentation

---

## ðŸŸ¡ Phase 3: Testing & Validation (IN PROGRESS)

**MÃ¥l:** Teste modeller og validere performance

### Tasks:

#### 3.1 Promptfoo Evaluation

```bash
# KÃ¸r evaluation
promptfoo eval -c ai-eval-config.yaml

# Se resultater
promptfoo view
```

**Test omrÃ¥der:**

- [ ] Dansk sprogkvalitet (alle modeller)
- [ ] Business tone (professionel vs casual)
- [ ] Email drafting quality
- [ ] Response times (sammenlign hastighed)
- [ ] Cost per request (verificer free tier)

**Success Criteria:**

- GLM-4.5 Air: â‰¥ 90% kvalitet pÃ¥ dansk
- Response time: < 3 sekunder
- Ingen hallucinations i business context
- 100% free tier coverage

#### 3.2 DeepEval Testing

```bash
# KÃ¸r Python tests
cd tests/ai
python deepeval-test.py
```

**Test cases:**

- [ ] Email summary relevancy (150 char max)
- [ ] Chat response faithfulness
- [ ] Invoice parameter extraction accuracy
- [ ] Calendar date parsing correctness

**Success Criteria:**

- Answer Relevancy: â‰¥ 0.85
- Faithfulness: â‰¥ 0.90
- Hallucination rate: < 5%

#### 3.3 Intent Detection Validation

**Test intent parsing med nye modeller:**

- [ ] "Opret lead" â†’ create_lead (â‰¥ 90% confidence)
- [ ] "Book mÃ¸de" â†’ book_meeting (â‰¥ 85% confidence)
- [ ] "Lav faktura" â†’ create_invoice (â‰¥ 90% confidence)
- [ ] "Tjek kalender" â†’ check_calendar (â‰¥ 85% confidence)

**Files to test:**

- `server/intent-actions.ts` (intent parsing)
- `server/ai-router.ts` (confidence thresholds)

#### 3.4 Email Intelligence Testing

**Test AI email features:**

- [ ] Email summaries (min 200 words â†’ max 150 chars)
- [ ] Label suggestions (5 categories, confidence scores)
- [ ] Thread analysis (multiple emails)
- [ ] Auto-labeling (â‰¥ 85% confidence)

**Files:**

- `server/ai-email-summary.ts`
- `server/ai-label-suggestions.ts`
- `server/email-analysis-engine.ts`

#### 3.5 Performance Benchmarking

```bash
# Playwright performance tests
npm run test:ai:performance
```

**Metrics to measure:**

- [ ] First token latency (< 500ms target)
- [ ] Total response time (< 3s target)
- [ ] Token throughput (tokens/sec)
- [ ] Memory usage during AI calls

**Success Criteria:**

- GLM-4.5 Air: Faster than old Gemma 3 27B
- No memory leaks
- Consistent performance over 100 requests

**Deliverables:** ðŸŽ¯

- Promptfoo evaluation report (HTML)
- DeepEval test results (JSON)
- Performance benchmark data
- Bug fixes for any issues found

---

## ðŸ”µ Phase 4: Production Rollout (PLANNED)

**MÃ¥l:** Deploy nye modeller til production

### Tasks:

#### 4.1 Pre-Production Validation

- [ ] KÃ¸r alle tests i staging environment
- [ ] Verify API key limits (OpenRouter free tier)
- [ ] Test fallback mechanism (hvis primary model fejler)
- [ ] Load test med 100 concurrent users

#### 4.2 Feature Flag Rollout

```typescript
// Gradual rollout med feature flags
enableModelRouting: true; // Enable for 10% â†’ 50% â†’ 100%
```

- [ ] 10% rollout â†’ Monitor for 24 timer
- [ ] 50% rollout â†’ Monitor for 48 timer
- [ ] 100% rollout â†’ Full deployment

**Monitoring:**

- Error rates (< 1% target)
- Response times (< 3s p95)
- User satisfaction (feedback)

#### 4.3 Production Deployment

```bash
# Deploy til production
npm run db:push:prod
npm run start
```

- [ ] Update `.env.prod` med nye model settings
- [ ] Deploy server changes
- [ ] Deploy client changes
- [ ] Update dokumentation

#### 4.4 Post-Deployment Monitoring

**Monitor i 1 uge:**

- [ ] Daily error logs review
- [ ] Performance metrics tracking
- [ ] User feedback collection
- [ ] Cost tracking (verificer free tier holder)

**Rollback plan:**

```bash
# Hvis problemer opstÃ¥r
OPENROUTER_MODEL=google/gemma-3-27b-it:free  # Revert
```

**Deliverables:** ðŸš€

- Production deployment complete
- Monitoring dashboard aktiv
- Zero downtime migration
- Full documentation updated

---

## ðŸŸ£ Phase 5: Optimization & Advanced Features (FUTURE)

**MÃ¥l:** Optimere og udvide AI capabilities

### Potential Enhancements:

#### 5.1 Advanced Model Routing

- [ ] Dynamic model selection baseret pÃ¥ user feedback
- [ ] A/B testing mellem modeller
- [ ] Cost/quality trade-off optimization
- [ ] User-specific model preferences

#### 5.2 Conversation Memory (Optional LangChain)

```typescript
// Hvis I beslutter jer for LangChain
import { ConversationChain } from "langchain/chains";
import { BufferMemory } from "langchain/memory";
```

- [ ] Evaluere LangChain v1.0 integration
- [ ] Implement conversation memory
- [ ] Multi-turn context retention
- [ ] Summary-based memory compression

#### 5.3 RAG Implementation (If Needed)

**Kun hvis I fÃ¥r brug for document search:**

- [ ] Vector database setup (Pinecone/ChromaDB)
- [ ] Document embedding pipeline
- [ ] Semantic search integration
- [ ] RAGAS evaluation

#### 5.4 Advanced Evaluation

- [ ] Custom evaluation metrics for Danish
- [ ] Business-specific quality scores
- [ ] User satisfaction correlation
- [ ] Continuous evaluation pipeline

**Deliverables:** ðŸŽ¯

- Optimized model routing
- Advanced features deployed
- Comprehensive evaluation system

---

## ðŸ“Š Success Metrics

### Key Performance Indicators (KPIs)

**Phase 3 Targets:**

- âœ… Model integration: 100% complete
- ðŸŽ¯ Test coverage: â‰¥ 80%
- ðŸŽ¯ Promptfoo score: â‰¥ 85/100
- ðŸŽ¯ DeepEval metrics: â‰¥ 0.85

**Phase 4 Targets:**

- ðŸŽ¯ Zero downtime deployment
- ðŸŽ¯ Error rate: < 1%
- ðŸŽ¯ Response time: < 3s (p95)
- ðŸŽ¯ User satisfaction: â‰¥ 4.5/5

**Phase 5 Targets:**

- ðŸŽ¯ Model routing optimization: â‰¥ 20% cost savings
- ðŸŽ¯ Advanced features adoption: â‰¥ 50% users
- ðŸŽ¯ Continuous evaluation: Daily reports

---

## ðŸš¦ Current Status

### âœ… Completed

- Phase 1: Model Integration (100%)
- Phase 2: Evaluation Setup (100%)

### ðŸŸ¡ In Progress

- Phase 3: Testing & Validation (20%)
  - Promptfoo: Not started
  - DeepEval: Not started
  - Intent validation: Not started
  - Performance: Not started

### â³ Upcoming

- Phase 4: Production Rollout (0%)
- Phase 5: Optimization (0%)

---

## ðŸŽ¯ Next Actions (Priority Order)

### 1. **Run Promptfoo Evaluation** (TODAY)

```bash
cd c:\Users\empir\Tekup\services\tekup-ai-v2
promptfoo eval -c ai-eval-config.yaml
promptfoo view  # Opens browser with results
```

### 2. **Run DeepEval Tests** (TODAY)

```bash
python tests/ai/deepeval-test.py
```

### 3. **Manual Testing** (THIS WEEK)

- Test Friday AI chat med nye modeller
- Test email summary generation
- Test label suggestions
- Test intent detection accuracy

### 4. **Review Results** (THIS WEEK)

- Analyze Promptfoo HTML report
- Review DeepEval metrics
- Document any issues
- Create bug fixes if needed

### 5. **Prepare for Phase 4** (NEXT WEEK)

- Fix any bugs from Phase 3
- Update production environment
- Create deployment checklist
- Schedule production deployment

---

## ðŸ“ Notes

### Environment Configuration

- âœ… Dev: GLM-4.5 Air (`z-ai/glm-4.5-air:free`)
- âœ… Prod: Ready for GLM-4.5 Air
- âœ… API Key: `sk-or-v1-6f45d089...` (existing key preserved)

### Model Costs

- **GLM-4.5 Air:** $0.00 (100% free)
- **All 6 models:** $0.00 (free tier)
- **Estimated savings:** 100% vs paid models

### Documentation

- âœ… `AI_MODEL_SELECTION_GUIDE.md` - Complete guide
- âœ… `AI_MODELS_UPGRADE_SUMMARY.md` - Quick reference
- âœ… `PHASE-PLAN.md` - This document

---

## ðŸ”— Quick Links

- **Model Router:** `server/model-router.ts`
- **AI Router:** `server/ai-router.ts`
- **LLM Core:** `server/_core/llm.ts`
- **Promptfoo Config:** `ai-eval-config.yaml`
- **DeepEval Tests:** `tests/ai/deepeval-test.py`
- **Documentation:** `docs/AI_MODEL_SELECTION_GUIDE.md`

---

**Last Updated:** November 8, 2025
**Next Review:** After Phase 3 completion
**Owner:** Tekup Development Team
