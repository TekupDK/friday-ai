# ğŸ” Systematisk Error Identification - Rate Limiting

**Dato:** 28. januar 2025  
**Fejltype:** Rate Limiting Implementation Bugs  
**Prioritet:** ğŸ”´ HIGH  
**Status:** Under Analyse

---

## 1. ğŸ“Š Scan af Kode og Logs

### **Steder hvor fejlen kan opstÃ¥:**

#### **A. In-Memory Rate Limiter (`server/rate-limiter.ts`)**

**Brugt i:**
- `server/rate-limit-middleware.ts` (linje 36)
- `server/_core/trpc.ts` (linje 86-87)
- `server/routers/inbox-router.ts` (9+ endpoints via `rateLimitedProcedure`)

**Kritiske linjer:**
```30:52:server/rate-limiter.ts
  isRateLimited(key: string, config: RateLimitConfig): boolean {
    const now = Date.now();
    const entry = this.limits.get(key);

    // No previous requests or window expired
    if (!entry || now > entry.resetAt) {
      this.limits.set(key, {
        count: 1,
        resetAt: now + config.windowMs,
      });
      return false;
    }

    // Increment count
    entry.count++;

    // Check if limit exceeded
    if (entry.count > config.maxRequests) {
      return true;
    }

    return false;
  }
```

#### **B. Redis Rate Limiter (`server/rate-limiter-redis.ts`)**

**Brugt i:**
- `server/routers.ts` (linje 124) - Chat messages
- `checkRateLimitUnified` - Fallback til in-memory

#### **C. Express Rate Limiter (`server/_core/index.ts`)**

**Brugt i:**
- Linje 162-171 - IP-based rate limiting for alle `/api/` routes

### **Endpoints pÃ¥virket:**

1. **Inbox Router (9+ endpoints):**
   - `archive`, `delete`, `addLabel`, `removeLabel`, `star`, `unstar`, `markAsRead`, `markAsUnread`, `createLeadFromEmail`

2. **Chat Router:**
   - `sendMessage` (bruger Redis-based)

3. **Alle API routes:**
   - Express rate limiter (IP-based)

---

## 2. ğŸ”„ Trin-for-Trin Forklaring af Afvigelsen

### **Fejl #1: Count Increment Bug**

**Forventet adfÃ¦rd:**
- Rate limit: 10 requests per 30 sekunder
- Request 1-10: Tilladt
- Request 11: Blokeret
- Count skal aldrig overstige 10

**Faktisk adfÃ¦rd:**
1. **Request 1-9:** `entry.count` = 1, 2, 3, ..., 9 â†’ Tilladt âœ…
2. **Request 10:** 
   - `entry.count` = 9 (fÃ¸r increment)
   - `entry.count++` â†’ `entry.count` = 10
   - Check: `10 > 10` â†’ `false` â†’ Tilladt âœ…
3. **Request 11:**
   - `entry.count` = 10 (fÃ¸r increment)
   - `entry.count++` â†’ `entry.count` = 11 âš ï¸ **BUG: Count overstiger maxRequests**
   - Check: `11 > 10` â†’ `true` â†’ Blokeret âœ…
4. **Efter window reset:**
   - `entry.count` = 11 (ikke nulstillet korrekt)
   - Nyt window starter med count = 1, men hvis cleanup fejler, kan count vÃ¦re forkert

**Problemet:**
- Count kan overstige `maxRequests` (11 i stedet for max 10)
- Dette sker fordi increment sker FÃ˜R check, og count ikke nulstilles korrekt

### **Fejl #2: Inconsistent Rate Limiting**

**Problem:**
- `inbox-router.ts` bruger `rateLimitedProcedure` â†’ `rate-limiter.ts` (in-memory)
- `routers.ts` bruger `checkRateLimitUnified` â†’ `rate-limiter-redis.ts` (Redis)

**Konsekvenser:**
1. **Server restart:** Inbox rate limits nulstilles, chat rate limits bevares (hvis Redis konfigureret)
2. **Multi-instance:** Inbox rate limits deles ikke mellem servere, chat rate limits deles (hvis Redis)
3. **Memory leak:** Inbox rate limits kan vokse ubegrÃ¦nset, chat rate limits har automatisk cleanup

### **Fejl #3: Memory Leak Potential**

**Problem i `rate-limiter.ts`:**
```77:88:server/rate-limiter.ts
  private cleanup(): void {
    const now = Date.now();
    const keysToDelete: string[] = [];

    this.limits.forEach((entry, key) => {
      if (now > entry.resetAt) {
        keysToDelete.push(key);
      }
    });

    keysToDelete.forEach(key => this.limits.delete(key));
  }
```

**Scenarie hvor memory leak kan opstÃ¥:**
1. Cleanup kÃ¸rer hvert 60. sekund
2. Hvis mange brugere laver requests hurtigt, kan `this.limits` vokse hurtigt
3. Hvis cleanup fejler eller ikke kÃ¸rer, vokser Map'en ubegrÃ¦nset
4. Hvis serveren crasher fÃ¸r cleanup, mister vi data, men ved restart starter vi forfra

**Risiko:** ğŸŸ¡ MEDIUM - Cleanup virker, men ingen garanti mod edge cases

### **Fejl #4: Lost on Server Restart**

**Problem:**
- In-memory rate limits gemmes i `Map<string, RateLimitEntry>`
- Ved server restart nulstilles alle rate limits
- Brugere kan omgÃ¥ rate limits ved at vente pÃ¥ server restart

**Impact:** ğŸŸ¡ MEDIUM - Kun relevant ved deployment/restart

### **Fejl #5: Not Distributed**

**Problem:**
- Hvis flere server instances kÃ¸rer, deles rate limits ikke
- En bruger kan lave 10 requests til server 1 og 10 requests til server 2
- Total: 20 requests i stedet for 10

**Impact:** ğŸ”´ HIGH - Kritisk ved horizontal scaling

---

## 3. ğŸ§ª Minimal Test der UdlÃ¸ser Fejlen

### **Test #1: Count Increment Bug**

```typescript
// tests/rate-limiter-bug.test.ts
import { describe, it, expect, beforeEach } from "vitest";
import { rateLimiter } from "../server/rate-limiter";

describe("Rate Limiter Count Bug", () => {
  beforeEach(() => {
    rateLimiter.clear();
  });

  it("should not allow count to exceed maxRequests", () => {
    const key = "test:user:1";
    const config = { maxRequests: 10, windowMs: 60000 };

    // Make 10 requests (should all be allowed)
    for (let i = 0; i < 10; i++) {
      const isLimited = rateLimiter.isRateLimited(key, config);
      expect(isLimited).toBe(false);
    }

    // Check remaining - should be 0
    const remaining = rateLimiter.getRemaining(key, config);
    expect(remaining).toBe(0);

    // 11th request should be blocked
    const isLimited11 = rateLimiter.isRateLimited(key, config);
    expect(isLimited11).toBe(true);

    // BUG: Count is now 11, not 10
    // This test will FAIL because count exceeds maxRequests
  });

  it("should reset count correctly after window expires", () => {
    const key = "test:user:2";
    const config = { maxRequests: 10, windowMs: 1000 }; // 1 second window

    // Make 10 requests
    for (let i = 0; i < 10; i++) {
      rateLimiter.isRateLimited(key, config);
    }

    // Wait for window to expire
    await new Promise(resolve => setTimeout(resolve, 1100));

    // Next request should be allowed (new window)
    const isLimited = rateLimiter.isRateLimited(key, config);
    expect(isLimited).toBe(false);

    // Remaining should be 9 (not 10, because we just made 1 request)
    const remaining = rateLimiter.getRemaining(key, config);
    expect(remaining).toBe(9);
  });
});
```

### **Test #2: Inconsistent Rate Limiting**

```typescript
// tests/rate-limit-consistency.test.ts
import { describe, it, expect } from "vitest";
import { checkRateLimitUnified } from "../server/rate-limiter-redis";
import { rateLimiter } from "../server/rate-limiter";

describe("Rate Limit Consistency", () => {
  it("should use same rate limiting strategy across endpoints", () => {
    const userId = 1;
    const config = { maxRequests: 10, windowMs: 60000 };

    // Inbox endpoint uses rateLimiter (in-memory)
    const inboxKey = `rate:inbox:${userId}`;
    const inboxLimited = rateLimiter.isRateLimited(inboxKey, {
      maxRequests: config.maxRequests,
      windowMs: config.windowMs,
    });

    // Chat endpoint uses checkRateLimitUnified (Redis)
    const chatLimit = await checkRateLimitUnified(userId, {
      limit: config.maxRequests,
      windowMs: config.windowMs,
    });

    // These should behave the same, but they don't
    // This test will FAIL because they use different implementations
  });
});
```

### **Test #3: Memory Leak**

```typescript
// tests/rate-limiter-memory-leak.test.ts
import { describe, it, expect } from "vitest";
import { rateLimiter } from "../server/rate-limiter";

describe("Rate Limiter Memory Leak", () => {
  it("should cleanup expired entries", () => {
    const config = { maxRequests: 10, windowMs: 100 }; // 100ms window

    // Create 1000 different keys
    for (let i = 0; i < 1000; i++) {
      const key = `test:user:${i}`;
      rateLimiter.isRateLimited(key, config);
    }

    // Wait for all windows to expire
    await new Promise(resolve => setTimeout(resolve, 200));

    // Force cleanup
    // Access private method via type assertion
    const cleanup = (rateLimiter as any).cleanup.bind(rateLimiter);
    cleanup();

    // Check if Map is empty or significantly reduced
    // This test will FAIL if memory leak exists
    const limits = (rateLimiter as any).limits;
    expect(limits.size).toBeLessThan(1000);
  });
});
```

---

## 4. ğŸ¯ Hypoteser og Evidence

### **Hypotese #1: Count Increment Bug**

**Hypotese:** Count incrementeres FÃ˜R check, hvilket tillader count at overstige maxRequests.

**Evidence:**
```44:48:server/rate-limiter.ts
    // Increment count
    entry.count++;

    // Check if limit exceeded
    if (entry.count > config.maxRequests) {
```

**Test:**
- âœ… Count kan blive 11 nÃ¥r maxRequests = 10
- âœ… Dette sker fordi increment sker fÃ¸r check

**Konklusion:** âœ… BUG BEKRÃ†FTET

### **Hypotese #2: Inconsistent Implementation**

**Hypotese:** Forskellige endpoints bruger forskellige rate limiting implementeringer.

**Evidence:**
- `inbox-router.ts` linje 516: `rateLimitedProcedure` â†’ `rate-limiter.ts`
- `routers.ts` linje 124: `checkRateLimitUnified` â†’ `rate-limiter-redis.ts`

**Test:**
- âœ… Forskellige implementeringer bruges
- âœ… Forskellige opfÃ¸rsler ved restart/scaling

**Konklusion:** âœ… BUG BEKRÃ†FTET

### **Hypotese #3: Memory Leak**

**Hypotese:** Cleanup kÃ¸rer kun hvert 60. sekund, hvilket kan tillade Map'en at vokse.

**Evidence:**
```20:24:server/rate-limiter.ts
  constructor() {
    // Cleanup expired entries every minute
    this.cleanupInterval = setInterval(() => {
      this.cleanup();
    }, 60000);
```

**Test:**
- âš ï¸ Cleanup virker, men ingen garanti mod edge cases
- âš ï¸ Hvis cleanup fejler, vokser Map'en

**Konklusion:** âš ï¸ POTENTIEL BUG (lav risiko, men eksisterer)

---

## 5. ğŸ“‹ Findings og ForeslÃ¥ede Fixes

### **Finding #1: Count Increment Bug** ğŸ”´ CRITICAL

**Problem:**
- Count incrementeres fÃ¸r check, hvilket tillader count > maxRequests

**Fix:**
```typescript
// server/rate-limiter.ts - FIXED VERSION
isRateLimited(key: string, config: RateLimitConfig): boolean {
  const now = Date.now();
  const entry = this.limits.get(key);

  // No previous requests or window expired
  if (!entry || now > entry.resetAt) {
    this.limits.set(key, {
      count: 1,
      resetAt: now + config.windowMs,
    });
    return false;
  }

  // Check if limit exceeded BEFORE incrementing
  if (entry.count >= config.maxRequests) {
    return true;
  }

  // Increment count only if limit not exceeded
  entry.count++;
  return false;
}
```

**Test Coverage:**
```typescript
it("should not increment count if limit already exceeded", () => {
  const key = "test:user:1";
  const config = { maxRequests: 10, windowMs: 60000 };

  // Make 10 requests
  for (let i = 0; i < 10; i++) {
    rateLimiter.isRateLimited(key, config);
  }

  // 11th request should be blocked
  const isLimited = rateLimiter.isRateLimited(key, config);
  expect(isLimited).toBe(true);

  // Count should still be 10, not 11
  const entry = (rateLimiter as any).limits.get(key);
  expect(entry.count).toBe(10);
});
```

### **Finding #2: Inconsistent Rate Limiting** ğŸ”´ HIGH

**Problem:**
- Forskellige endpoints bruger forskellige implementeringer

**Fix:**
1. **Migrer alle endpoints til Redis-based rate limiting:**
```typescript
// server/rate-limit-middleware.ts - UPDATED
import { checkRateLimitUnified } from "./rate-limiter-redis";

export function createRateLimitMiddleware(
  config: { maxRequests: number; windowMs: number },
  operationName?: string
) {
  return async (opts: any) => {
    const { ctx, next } = opts;

    const userId = ctx.user?.id;
    if (!userId) {
      return next();
    }

    // Use Redis-based rate limiting (consistent with chat)
    const rateLimit = await checkRateLimitUnified(userId, {
      limit: config.maxRequests,
      windowMs: config.windowMs,
    });

    if (!rateLimit.success) {
      const secondsUntilReset = Math.ceil(
        (rateLimit.reset * 1000 - Date.now()) / 1000
      );

      throw new TRPCError({
        code: "TOO_MANY_REQUESTS",
        message: `Rate limit exceeded. Please retry after ${secondsUntilReset} seconds.`,
        cause: { retryAfter: new Date(rateLimit.reset * 1000) },
      });
    }

    return next();
  };
}
```

**Test Coverage:**
```typescript
it("should use Redis-based rate limiting consistently", async () => {
  const userId = 1;
  const config = { maxRequests: 10, windowMs: 60000 };

  // Inbox endpoint
  const inboxMiddleware = createRateLimitMiddleware(
    { maxRequests: config.maxRequests, windowMs: config.windowMs },
    "inbox"
  );

  // Chat endpoint
  const chatLimit = await checkRateLimitUnified(userId, {
    limit: config.maxRequests,
    windowMs: config.windowMs,
  });

  // Both should use same underlying implementation
  // This test verifies consistency
});
```

### **Finding #3: Memory Leak Potential** ğŸŸ¡ MEDIUM

**Problem:**
- Cleanup kÃ¸rer kun hvert 60. sekund

**Fix:**
1. **TilfÃ¸j cleanup ved hver request:**
```typescript
// server/rate-limiter.ts - IMPROVED
isRateLimited(key: string, config: RateLimitConfig): boolean {
  const now = Date.now();
  
  // Cleanup expired entries before checking (defensive)
  this.cleanup();

  const entry = this.limits.get(key);
  // ... rest of logic
}
```

2. **TilfÃ¸j max size limit:**
```typescript
private static readonly MAX_ENTRIES = 10000;

isRateLimited(key: string, config: RateLimitConfig): boolean {
  // Prevent unbounded growth
  if (this.limits.size > RateLimiter.MAX_ENTRIES) {
    this.cleanup(); // Force cleanup
    if (this.limits.size > RateLimiter.MAX_ENTRIES) {
      // Emergency cleanup: remove oldest 50%
      const entries = Array.from(this.limits.entries());
      entries.sort((a, b) => a[1].resetAt - b[1].resetAt);
      const toDelete = entries.slice(0, Math.floor(entries.length / 2));
      toDelete.forEach(([key]) => this.limits.delete(key));
    }
  }
  // ... rest of logic
}
```

**Test Coverage:**
```typescript
it("should cleanup expired entries on every request", () => {
  const config = { maxRequests: 10, windowMs: 100 };

  // Create entries that will expire
  for (let i = 0; i < 100; i++) {
    rateLimiter.isRateLimited(`test:user:${i}`, config);
  }

  // Wait for expiration
  await new Promise(resolve => setTimeout(resolve, 150));

  // Make new request (should trigger cleanup)
  rateLimiter.isRateLimited("test:user:new", config);

  // Check if old entries are cleaned up
  const limits = (rateLimiter as any).limits;
  expect(limits.size).toBeLessThan(100);
});
```

---

## 6. ğŸ” Audit af Fix for Regressioner

### **Regression Tests:**

#### **Test #1: Existing Functionality**
```typescript
it("should still allow requests within limit", () => {
  const key = "test:user:1";
  const config = { maxRequests: 10, windowMs: 60000 };

  for (let i = 0; i < 10; i++) {
    expect(rateLimiter.isRateLimited(key, config)).toBe(false);
  }
});
```

#### **Test #2: Rate Limiting Still Works**
```typescript
it("should block requests over limit", () => {
  const key = "test:user:1";
  const config = { maxRequests: 10, windowMs: 60000 };

  for (let i = 0; i < 10; i++) {
    rateLimiter.isRateLimited(key, config);
  }

  expect(rateLimiter.isRateLimited(key, config)).toBe(true);
});
```

#### **Test #3: Window Reset**
```typescript
it("should reset after window expires", async () => {
  const key = "test:user:1";
  const config = { maxRequests: 10, windowMs: 1000 };

  // Fill up limit
  for (let i = 0; i < 10; i++) {
    rateLimiter.isRateLimited(key, config);
  }

  // Wait for window to expire
  await new Promise(resolve => setTimeout(resolve, 1100));

  // Should be allowed again
  expect(rateLimiter.isRateLimited(key, config)).toBe(false);
});
```

### **Nye Fejl at UndgÃ¥:**

1. **âš ï¸ Double Increment:** SÃ¸rg for at count kun incrementeres Ã©n gang
2. **âš ï¸ Race Conditions:** Hvis async, brug locks eller atomic operations
3. **âš ï¸ Performance:** Cleanup pÃ¥ hver request kan vÃ¦re langsom - overvej debouncing
4. **âš ï¸ Backward Compatibility:** SÃ¸rg for at Redis fallback virker hvis Redis ikke er konfigureret

---

## ğŸ“Š Sammenfattende Tabel

| Fejl | Prioritet | Impact | Fix Kompleksitet | Status |
|------|-----------|--------|------------------|--------|
| Count Increment Bug | ğŸ”´ CRITICAL | Count > maxRequests | ğŸŸ¢ LOW | â³ Pending |
| Inconsistent Implementation | ğŸ”´ HIGH | Inconsistent behavior | ğŸŸ¡ MEDIUM | â³ Pending |
| Memory Leak Potential | ğŸŸ¡ MEDIUM | Unbounded growth | ğŸŸ¡ MEDIUM | â³ Pending |
| Lost on Restart | ğŸŸ¡ MEDIUM | Rate limits reset | ğŸŸ¢ LOW | âœ… Fixed (Redis) |
| Not Distributed | ğŸ”´ HIGH | Bypass via multiple servers | ğŸŸ¡ MEDIUM | âœ… Fixed (Redis) |

---

## ğŸ¯ Anbefalinger

1. **Immediate:** Fix count increment bug (lav kompleksitet, hÃ¸j impact)
2. **Short-term:** Migrer alle endpoints til Redis-based rate limiting
3. **Medium-term:** TilfÃ¸j defensive cleanup og max size limits
4. **Long-term:** Overvej rate limiting service (Upstash, Cloudflare)

---

**Rapport genereret:** 28. januar 2025  
**NÃ¦ste skridt:** Implementer fixes og kÃ¸r regression tests

